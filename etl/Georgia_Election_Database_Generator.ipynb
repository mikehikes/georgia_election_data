{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Source Data\n",
    "The Georgia Election Data Jupyter Notebook uses a sqlite3 database to store the entire corpus of Georgia Election data. In lieu of sqlite, any other SQL-based database could certainly be used; SQL lite, however, is used to reduce any costs (AWS, GCS, etc.) associated with working with a live SQL database.\n",
    "\n",
    "### Prerequisites\n",
    "1. Python >= 3.6\n",
    "2. CLI version of Git\n",
    "3. OSX/Linux folder structure\n",
    "3. 3gb of space to clone the repository and generate the database\n",
    "4. Tested with 20 gb of memory, may work with 16 gb.\n",
    "5. Packages required: tqdm\n",
    "\n",
    "### Source data location\n",
    "\n",
    "A copy of the full source data files is maintained on this repo, for purposes of reproducing the methods used to convert the original fixed width files into a SQLite database.\n",
    "\n",
    "Alternatively, you can download the files directly from the State of Georgia website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to access source files from State of Georgia -- OPTIONAL\n",
    "\n",
    "(Directions are functional as of August 2019)\n",
    "\n",
    "#### 2013-2019\n",
    "Step 1: Go to https://elections.sos.ga.gov/Elections/voterhistory.do\n",
    "Step 2: Select the election year, and then download the `Full Year File`\n",
    "Step 3: Download each of the ZIP files into a folder accessible to your Python instance\n",
    "\n",
    "#### 1996-2012\n",
    "Step 1: Go to https://elections.sos.ga.gov/Elections/voterhistoryprevious.do\n",
    "Step 2: Download each year's zip file into a folder accessible to your Python instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the location of the \"original\" data, \n",
    "# meaning the data from the Secretary of State's\n",
    "# web site\n",
    "\n",
    "original_data_folder = '/original_data_20190709'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this notebook was not loaded as part of a repository,\n",
    "# the following settings will be used to save the cloned\n",
    "# repository\n",
    "\n",
    "working_root_folder = '/tmp/ga_elect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repo_check_clone(force=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function checks if the notebook is running from a cloned folder, or\n",
    "    if the notebook was downloaded individually from the repo.\n",
    "    \n",
    "    If the notebook is running in a repo, the folder of the repo will be returned.\n",
    "    \n",
    "    If not, an option will be provided to re-clone the repo.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(os.getcwd() + '/original_data_20190709') and force is False:\n",
    "        print(\"Notebook appears to be running within a cloned repo. Skipping repo clone.\")\n",
    "        working_root_folder = os.getcwd()\n",
    "        print(f\"Setting working root folder to {working_root_folder}\")\n",
    "    else:\n",
    "        print(\"Notebook does not appear to be running within a cloned repo.\")\n",
    "        input_res = input(\"Type Y to clone the repo. NoteL This is a 750MB download.\")\n",
    "        if input_res == 'Y':\n",
    "            print(f\"Creating {working_root_folder}\")\n",
    "            try:\n",
    "                os.mkdir(working_root_folder)\n",
    "                print(\"Folder created\")\n",
    "                !git clone git@github.com:solidgose/ga_elect.git {working_root_folder + '/.'}\n",
    "            except FileExistsError as fee:\n",
    "                print(\"The folder already exists. Please empty the folder if you wish to recreate\")\n",
    "            except Exception as e:\n",
    "                print(\"Other error\", e)\n",
    "    return working_root_folder            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook appears to be running within a cloned repo. Skipping repo clone.\n",
      "Setting working root folder to /home/michaelhandelman/ga_election_code/ga_elect\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the notebook is running inside of a repository.\n",
    "# If not, clone the respository.\n",
    "working_root_folder = repo_check_clone(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are utility functions used for ETL purposes of the original source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_2012_prior(in_line):\n",
    "\n",
    "    in_line = in_line.decode('utf-8')\n",
    "    \n",
    "    county_no = in_line[0:3]\n",
    "    reg_no = in_line[3:11]\n",
    "    election_date = in_line[11:19]\n",
    "    election_type = in_line[19:22].strip()\n",
    "    party = in_line[22:23].strip()\n",
    "    absentee = in_line[23:24]\n",
    "    \n",
    "    # dates for this time series are presented as day-month-year\n",
    "    # we will standardize these dates to year-month-day to reduce\n",
    "    # confusion and match the date format of the 2013 and onwards data\n",
    "    #print(election_date)\n",
    "    election_date = election_date[4:] + '-' + election_date[0:2] + '-' + election_date[2:4]\n",
    "    \n",
    "    # standardize party indicator from primary election records: single char\n",
    "    # D -> Democrat\n",
    "    # R -> Republican\n",
    "    # N -> Non-Partisan\n",
    "    \n",
    "    if party == 'NP':\n",
    "        party = 'N'\n",
    "    elif party != 'D' and party != 'R' and party != 'N':\n",
    "        party = \"\"\n",
    "\n",
    "\n",
    "    if absentee == 'Y':\n",
    "        absentee = True\n",
    "    else:\n",
    "        absentee = False\n",
    "        \n",
    "    return (0,county_no, reg_no, election_date,election_type, party, absentee,None,None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-02-03\n",
      "2014-02-03\n"
     ]
    }
   ],
   "source": [
    "test_date = '20140203'\n",
    "election_date = election_date[0:4] + '-' + election_date[4:6] + '-' + election_date[6:]\n",
    "\n",
    "\n",
    "election_date = '02032014'\n",
    "election_date = election_date[4:] + '-' + election_date[0:2] + '-' + election_date[2:4]\n",
    "print(election_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_2013_post(in_line):\n",
    "\n",
    "    # Convert all strings to utf-8 for international standarization purposes\n",
    "    in_line = in_line.decode('utf-8')\n",
    "    \n",
    "    county_no = in_line[0:3].strip()\n",
    "    reg_no = in_line[3:11].strip()\n",
    "    election_date = in_line[11:19].strip()\n",
    "    election_type = in_line[19:22].strip()\n",
    "    party= in_line[22:24].strip()\n",
    "    absentee =in_line[24:25].strip()\n",
    "    provisional = in_line[25:26].strip()\n",
    "    supplemental = in_line[26:27].strip()\n",
    "    \n",
    "    election_date = election_date[0:4] + '-' + election_date[4:6] + '-' + election_date[6:]    \n",
    "    # the election date is already in YYYY-MM-DD, so no additional action needed\n",
    "    \n",
    "    # standardize party indicator from primary election records: single char\n",
    "    # D -> Democrat\n",
    "    # R -> Republican\n",
    "    # N -> Non-Partisan\n",
    "    \n",
    "    if party == 'NP':\n",
    "        party = 'N'\n",
    "    elif party != 'D' and party != 'R' and party != 'N':\n",
    "        party = None\n",
    "\n",
    "    # Convert absentee flags to True/False\n",
    "\n",
    "    if absentee == 'Y':\n",
    "        absentee = True\n",
    "    else:\n",
    "        absentee = False\n",
    "\n",
    "    # Convert provisional flags to True/False\n",
    "\n",
    "    if provisional == 'Y':\n",
    "        provisional = True\n",
    "    else:\n",
    "        provisional = False        \n",
    "\n",
    "    # Convert supplemental flags to True/False\n",
    "    \n",
    "    if supplemental == 'Y':\n",
    "        supplemental = True\n",
    "    else:\n",
    "        supplemental = False       \n",
    "    return (1,county_no, reg_no, election_date,election_type, party, absentee,supplemental,absentee)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fwf_to_sqlitedb(source_files_loc=None,dest_db_loc=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes the source data files and builds a sqlite database.\n",
    "    CSVs are being used in lieu of pandas dataframes for the source data because\n",
    "    the memory footprint and CPU overhead of 78 million records requires an\n",
    "    un-needed quantity of those resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # first, find all available files in the source location\n",
    "    \n",
    "    list_of_files = glob(source_files_loc + '/*')\n",
    "    list_of_files.sort()\n",
    "    print(f\"Found {len(list_of_files)} to process.\")\n",
    "    \n",
    "    range_known_files = set(range(1996,2020))\n",
    "    range_found_files = set()\n",
    "    \n",
    "    \n",
    "    print(f\"Creating database in the {dest_db_loc} folder\")\n",
    "    \n",
    "    for f in tqdm(list_of_files, desc=\"Individual file processing progress\", position=0):\n",
    "            range_found_files.add(int(os.path.basename(f.split('.')[0])))\n",
    "   \n",
    "    #print(range_known_files)\n",
    "    #print(range_found_files)\n",
    "\n",
    "    proceed = False\n",
    "    \n",
    "    if len(range_known_files - range_found_files) == 0:\n",
    "        print('All Files Found')\n",
    "        proceed = True\n",
    "    \n",
    "    else:\n",
    "        print(\"The following files were expected but not found:\")\n",
    "        print(list(range_known_files-range_found_files))\n",
    "        input_response = input(\"There are missing files. Type Y to proceed.\")\n",
    "        if input_response == 'Y':\n",
    "            proceed = True\n",
    "    \n",
    "    \n",
    "    if proceed:\n",
    "            \n",
    "        db = sqlite3.connect(dest_db_loc)\n",
    "        c = db.cursor()\n",
    "        c.execute('drop table if exists ga_elect_data;')\n",
    "        db.commit()\n",
    "        c = db.cursor()\n",
    "        c.execute('''\n",
    "                   CREATE TABLE ga_elect_data(\n",
    "                   vintage INT,\n",
    "                   county_no TEXT,\n",
    "                   reg_no TEXT, \n",
    "                   election_date TEXT,\n",
    "                   election_type TEXT, \n",
    "                   party TEXT,\n",
    "                   absentee BOOLEAN,\n",
    "                   supplemental BOOLEAN,\n",
    "                   provisional BOOLEAN) \n",
    "                ''')\n",
    "        db.commit()\n",
    "        \n",
    "        # now load the files\n",
    "        \n",
    "        pre_2012_range = set(range(1996,2013))\n",
    "        post_2013_range = set(range(2013,2020))\n",
    "        \n",
    "        for f in tqdm(list_of_files):\n",
    "            with ZipFile(f).open(ZipFile(f).namelist()[0]) as ff:\n",
    "                    data = ff.readlines()\n",
    "                            \n",
    "                    if int(os.path.basename(f).split(\".\")[0]) in pre_2012_range:\n",
    "                        parsed_data = list(map(parse_function_2012_prior,data))\n",
    "\n",
    "                    elif int(os.path.basename(f).split(\".\")[0]) in post_2013_range:\n",
    "                        parsed_data = list(map(parse_function_2013_post,data))\n",
    "    \n",
    "            print(f\"Loading {os.path.basename(f)} into the sqlite database\")\n",
    "            c = db.cursor()\n",
    "            c.executemany(\"INSERT INTO ga_elect_data VALUES (?,?, ?, ?, ?, ?, ?, ?, ?)\", parsed_data)\n",
    "            db.commit()\n",
    "            print(f\"Loaded {os.path.basename(f)} into the sqlite database\")\n",
    "            \n",
    "    db.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the database\n",
    "\n",
    "The following code generates the sqlite database from the source data. This process should take 5-10 minutes to complete, depending on available computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db\n",
      "The curent database name still exists. Type Y if you want to re-create the databaseY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Individual file processing progress: 100%|██████████| 24/24 [00:00<00:00, 54648.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 to process.\n",
      "Creating database in the /home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db folder\n",
      "All Files Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1996.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:34<13:09, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1996.zip into the sqlite database\n",
      "Loading 1997.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:42<09:42, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1997.zip into the sqlite database\n",
      "Loading 1998.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [01:09<09:18, 26.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1998.zip into the sqlite database\n",
      "Loading 1999.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [01:14<06:40, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1999.zip into the sqlite database\n",
      "Loading 2000.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [01:52<08:04, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000.zip into the sqlite database\n",
      "Loading 2001.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [01:58<05:56, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2001.zip into the sqlite database\n",
      "Loading 2002.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [02:27<06:22, 22.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2002.zip into the sqlite database\n",
      "Loading 2003.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [02:32<04:37, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2003.zip into the sqlite database\n",
      "Loading 2004.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [03:22<06:43, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2004.zip into the sqlite database\n",
      "Loading 2005.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [03:29<04:53, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2005.zip into the sqlite database\n",
      "Loading 2006.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [03:57<05:00, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2006.zip into the sqlite database\n",
      "Loading 2007.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [04:03<03:37, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2007.zip into the sqlite database\n",
      "Loading 2008.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [05:16<06:20, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2008.zip into the sqlite database\n",
      "Loading 2009.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [05:23<04:20, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2009.zip into the sqlite database\n",
      "Loading 2010.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [06:00<04:26, 29.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2010.zip into the sqlite database\n",
      "Loading 2011.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [06:11<03:10, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2011.zip into the sqlite database\n",
      "Loading 2012.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [07:06<03:52, 33.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2012.zip into the sqlite database\n",
      "Loading 2013.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [07:13<02:32, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2013.zip into the sqlite database\n",
      "Loading 2014.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [07:50<02:24, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2014.zip into the sqlite database\n",
      "Loading 2015.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [07:56<01:27, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2015.zip into the sqlite database\n",
      "Loading 2016.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [09:03<01:46, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016.zip into the sqlite database\n",
      "Loading 2017.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [09:16<00:57, 28.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2017.zip into the sqlite database\n",
      "Loading 2018.zip into the sqlite database\n"
     ]
    }
   ],
   "source": [
    "# Set the path for outputting the database file\n",
    "\n",
    "original_data_full_path = working_root_folder + original_data_folder\n",
    "database_out_path = working_root_folder +  '/database/'\n",
    "\n",
    "# the sqlite database will be saved here\n",
    "database_name = 'ga_elect2.db'\n",
    "\n",
    "# Check first to see if this file exists\n",
    "# If so, we want to give the option to delete it\n",
    "# since it may be locked or corrupted\n",
    "\n",
    "print(database_out_path + database_name)\n",
    "is_database_exists = os.path.exists(database_out_path + database_name)\n",
    "\n",
    "confirm = None \n",
    "\n",
    "if is_database_exists:\n",
    "    confirm = input(\"The curent database name still exists. Type Y if you want to re-create the database\")\n",
    "\n",
    "if confirm == 'Y':    \n",
    "    convert_fwf_to_sqlitedb(original_data_full_path, database_out_path + database_name)\n",
    "else:\n",
    "    print(\"Keeping existing database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function/\n",
    "\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "c.execute('''SELECT count(*) FROM ga_elect_data''')\n",
    "assert(c.fetchall()[0][0]) == 76453445\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding helper tables\n",
    "\n",
    "There is one helper table that will also be added to the database. This helper table maps the election_type field to indicate if the field reflects a _primary_ election, a _primary runoff_ election, a _general_ election, or another type of vote.\n",
    "\n",
    "This mapping is needed because the election_type coding has either 1) not been consistent from election to election or 2) a new election_type code was created when a ballot combined two types of elections. For example, a general election added to a recall election.\n",
    "\n",
    "The repo includes a file `election_type_mapping.csv` that contains a manual classification between the election types and the above manual classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db\n",
      "found helper data here:/home/michaelhandelman/ga_election_code/ga_elect/election_type_mapping.csv\n",
      "Table created\n",
      "Data uploaded\n"
     ]
    }
   ],
   "source": [
    "print(f\"Opening {database_out_path + database_name}\")\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "\n",
    "manual_classification_file_loc = working_root_folder + '/election_type_mapping.csv'\n",
    "\n",
    "if os.path.exists(manual_classification_file_loc):\n",
    "    print(\"found helper data here:\" + manual_classification_file_loc)\n",
    "\n",
    "    \n",
    "# load the file into a list of tuples\n",
    "\n",
    "input_str = open(manual_classification_file_loc, 'r').readlines()\n",
    "input_str_list = [tuple(l.strip().split(',')) for l in input_str]\n",
    "# remove header\n",
    "input_str_list = input_str_list[1:]\n",
    "\n",
    "c.execute('drop table if exists ga_elect_manual_classification;')\n",
    "db.commit()\n",
    "c = db.cursor()\n",
    "c.execute('''\n",
    "           CREATE TABLE ga_elect_manual_classification(\n",
    "           election_type_index INT,\n",
    "           election_type TEXT,\n",
    "           election_type_description TEXT, \n",
    "           manual_classification TEXT)\n",
    "           ''')\n",
    "db.commit()\n",
    "print(\"Table created\")\n",
    "\n",
    "c = db.cursor()\n",
    "c.executemany(\"INSERT INTO ga_elect_manual_classification VALUES (?,?, ?, ?)\", input_str_list)\n",
    "db.commit()\n",
    "print(\"Data uploaded\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming that this new table was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function/\n",
    "\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "c.execute('''SELECT count(*) FROM ga_elect_manual_classification''')\n",
    "assert(c.fetchall()[0][0] == 37)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
