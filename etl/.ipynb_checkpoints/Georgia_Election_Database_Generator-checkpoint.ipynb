{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Georgia Election Source Data\n",
    "\n",
    "The notebooks in this repo require a processed, cleaned, and normalized version of the source election data from the State of Georgia's Office of Secretary of State. This notebook, and an associated python script, will create a sqlite3-based database that subsequent notebooks will use as a data source.\n",
    "\n",
    "### Why sqlite3?\n",
    "This library is used to permit running the Jupyter notebooks on a laptop or Google Colab-type environment, without the need for purchasing or establishing a Google Cloud Compute (GCS) or AWS Resource. Future versions of this notebook may include the option to use paid-database resources on one or both of these services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "1. Anaconda Python is used to create the environment needed to operate this notebook, with an environment defined in `environment.yml`. Anaconda Python may be [downloaded without cost](https://www.anaconda.com/distribution/#download-section) for Linux, Windows, or macOS.\n",
    "\n",
    "\n",
    "2. This repo should be cloned from GitHub; the notebook may not operate as expected if individual notebooks are downloaded without supporting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_loc = 'source_data'\n",
    "data_vintage_loc = '20190709'\n",
    "\n",
    "working_directory = None\n",
    "working_directory = '/home/michael/git_repos/georgia_election_data'\n",
    "\n",
    "first_years_data = 1996\n",
    "last_years_data = 2019\n",
    "\n",
    "database_location = 'processed_data'\n",
    "dest_db_name = 'election_data.db'\n",
    "dest_db_table_name = 'gaelect'\n",
    "\n",
    "batch_size = int(1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Source Data\n",
    "\n",
    "Included in this repo are the source ZIP files obtained from the State of Georgia Secretary of State in August 2019. _These files are provided without assertions to accuracy_. To re-acquire or download the source files, you may follow the following instructions.\n",
    "\n",
    "#### 2013-2019\n",
    "Step 1: Go to https://elections.sos.ga.gov/Elections/voterhistory.do\n",
    "Step 2: Select the election year, and then download the `Full Year File`\n",
    "Step 3: Download each of the ZIP files into a folder accessible to your Python instance\n",
    "\n",
    "#### 1996-2012\n",
    "Step 1: Go to https://elections.sos.ga.gov/Elections/voterhistoryprevious.do\n",
    "Step 2: Download each year's zip file into a folder accessible to your Python instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirming the existence and integrity of the source data\n",
    "\n",
    "The following cells indicate configuration parameters that describe the location and composition of the source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory is /home/michael/git_repos/georgia_election_data/etl\n",
      "Found all expected data.\n"
     ]
    }
   ],
   "source": [
    "print(f'Current Working Directory is {os.getcwd()}')\n",
    "\n",
    "if working_directory is None:\n",
    "    working_directory = os.getcwd()\n",
    "\n",
    "if working_directory.split('/')[-1] != 'georgia_election_data':\n",
    "    print(\"Change the new_working_directory folder to indicate the root folder of this notebook\")\n",
    "        \n",
    "else:    \n",
    "    list_of_known_years_election_data = [str(a) + '.zip' for a in list(range(first_years_data,last_years_data+1))]\n",
    "\n",
    "found_files = sorted(os.listdir(working_directory + f'/{source_data_loc}' + f'/{data_vintage_loc}'))\n",
    "matches = found_files == list_of_known_years_election_data\n",
    "if matches:\n",
    "    print(\"Found all expected data.\")\n",
    "else:\n",
    "    print(f\"Expected data not found. Missing files are {list(set(list_of_known_years_election_data)-set(found_files))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Loading Functions\n",
    "\n",
    "These functions load the two available vintages of Georgia Voter Data: data for years 2012 and prior, and data for years 2013 and subsequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_2012_prior(in_line):\n",
    "\n",
    "    in_line = in_line.decode('utf-8')\n",
    "    \n",
    "    county_no = in_line[0:3]\n",
    "    reg_no = in_line[3:11]\n",
    "    election_date = in_line[11:19]\n",
    "    election_type = in_line[19:22].strip()\n",
    "    party = in_line[22:23].strip()\n",
    "    absentee = in_line[23:24]\n",
    "    \n",
    "    # dates for this time series are presented as day-month-year\n",
    "    # we will standardize these dates to year-month-day to reduce\n",
    "    # confusion and match the date format of the 2013 and onwards data\n",
    "    #print(election_date)\n",
    "    election_date = election_date[4:] + '-' + election_date[0:2] + '-' + election_date[2:4]\n",
    "    \n",
    "    # standardize party indicator from primary election records: single char\n",
    "    # D -> Democrat\n",
    "    # R -> Republican\n",
    "    # N -> Non-Partisan\n",
    "    \n",
    "    if party == 'NP':\n",
    "        party = 'N'\n",
    "    elif party != 'D' and party != 'R' and party != 'N':\n",
    "        party = \"\"\n",
    "\n",
    "\n",
    "    if absentee == 'Y':\n",
    "        absentee = True\n",
    "    else:\n",
    "        absentee = False\n",
    "        \n",
    "    return (0,county_no, reg_no, election_date,election_type, party, absentee,None,None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function_2013_post(in_line):\n",
    "\n",
    "    # Convert all strings to utf-8 for international standarization purposes\n",
    "    in_line = in_line.decode('utf-8')\n",
    "    \n",
    "    county_no = in_line[0:3].strip()\n",
    "    reg_no = in_line[3:11].strip()\n",
    "    election_date = in_line[11:19].strip()\n",
    "    election_type = in_line[19:22].strip()\n",
    "    party= in_line[22:24].strip()\n",
    "    absentee =in_line[24:25].strip()\n",
    "    provisional = in_line[25:26].strip()\n",
    "    supplemental = in_line[26:27].strip()\n",
    "    \n",
    "    election_date = election_date[0:4] + '-' + election_date[4:6] + '-' + election_date[6:]    \n",
    "    # the election date is already in YYYY-MM-DD, so no additional action needed\n",
    "    \n",
    "    # standardize party indicator from primary election records: single char\n",
    "    # D -> Democrat\n",
    "    # R -> Republican\n",
    "    # N -> Non-Partisan\n",
    "    \n",
    "    if party == 'NP':\n",
    "        party = 'N'\n",
    "    elif party != 'D' and party != 'R' and party != 'N':\n",
    "        party = None\n",
    "\n",
    "    # Convert absentee flags to True/False\n",
    "\n",
    "    if absentee == 'Y':\n",
    "        absentee = True\n",
    "    else:\n",
    "        absentee = False\n",
    "\n",
    "    # Convert provisional flags to True/False\n",
    "\n",
    "    if provisional == 'Y':\n",
    "        provisional = True\n",
    "    else:\n",
    "        provisional = False        \n",
    "\n",
    "    # Convert supplemental flags to True/False\n",
    "    \n",
    "    if supplemental == 'Y':\n",
    "        supplemental = True\n",
    "    else:\n",
    "        supplemental = False       \n",
    "    return (1,county_no, reg_no, election_date,election_type, party, absentee,supplemental,absentee)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_elections_db_exists(full_path_to_db):\n",
    "    found = False\n",
    "    # first, check to see if the database file itself exists\n",
    "    if os.path.exists(full_path_to_db):\n",
    "        db = sqlite3.connect(full_path_to_db)\n",
    "        c = db.cursor()\n",
    "        c.execute(f'SELECT name FROM sqlite_master WHERE type=\\'table\\' AND name={dest_db_table_name}')\n",
    "    else:\n",
    "        return found\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_lines_iterator(source_file):\n",
    "    with ZipFile(source_file).open(ZipFile(source_file).namelist()[0]) as file:\n",
    "        for i in file:\n",
    "            yield i\n",
    "            \n",
    "#list_of_files = glob(working_directory + f'/{source_data_loc}' + f'/{data_vintage_loc}' + '/*')\n",
    "#source_file = list_of_files[1]\n",
    "#lines_required = batch_size\n",
    "\n",
    "# get number of lines in text file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_etl_batches(source_file):\n",
    "    with ZipFile(source_file).open(ZipFile(source_file).namelist()[0]) as f:\n",
    "        line_count = sum(1 for _ in f)\n",
    "        print(f'Datafile {ZipFile(source_file).namelist()[0]} contains {line_count} records')\n",
    "        in_range = list(range(line_count))\n",
    "        out_batch = [in_range[i * batch_size:(i + 1) * batch_size] for i in range((len(in_range) + batch_size - 1) // batch_size )] \n",
    "        return({'source_file':source_file,\n",
    "                'line_count':line_count,\n",
    "                'batches':[(min(b), max(b)) for b in out_batch]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 to process.\n",
      "Datafile Voter History 1996.txt contains 4644200 records\n",
      "Datafile Voter History 1997.txt contains 959435 records\n",
      "Datafile Voter History 1998.txt contains 3553259 records\n",
      "Datafile Voter History 1999.txt contains 539933 records\n",
      "Datafile Voter History 2000.txt contains 5046847 records\n",
      "Datafile Voter History 2001.txt contains 708042 records\n",
      "Datafile Voter History 2002.txt contains 3731165 records\n",
      "Datafile Voter History 2003.txt contains 602137 records\n",
      "Datafile Voter History 2004.txt contains 6399634 records\n",
      "Datafile Voter History 2005.txt contains 651522 records\n",
      "Datafile Voter History 2006.txt contains 3796362 records\n",
      "Datafile Voter History 2007.txt contains 752749 records\n",
      "Datafile Voter History 2008.txt contains 9628482 records\n",
      "Datafile Voter History 2009.txt contains 560700 records\n",
      "Datafile Voter History 2010.txt contains 4841793 records\n",
      "Datafile Voter History 2011.txt contains 877001 records\n",
      "Datafile Voter History 2012.txt contains 7036094 records\n",
      "Datafile 2013.TXT contains 630456 records\n",
      "Datafile 2014.TXT contains 4271520 records\n",
      "Datafile 2015.TXT contains 566225 records\n",
      "Datafile 2016.TXT contains 7727053 records\n",
      "Datafile 2017.TXT contains 1264641 records\n",
      "Datafile 2018.TXT contains 7458650 records\n",
      "Datafile 2019.TXT contains 205545 records\n"
     ]
    }
   ],
   "source": [
    "list_of_files = glob(working_directory + f'/{source_data_loc}' + f'/{data_vintage_loc}' + '/*')\n",
    "list_of_files.sort()\n",
    "print(f\"Found {len(list_of_files)} to process.\")\n",
    "ret_batches = list(map(create_etl_batches, list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 76453421 total voting records and 87 batches in the data sets\n"
     ]
    }
   ],
   "source": [
    "number_of_records = sum([r['batches'][-1][1] for r in ret_batches])\n",
    "number_of_batches = sum([len(r['batches']) for r in ret_batches])\n",
    "print(f'There are {number_of_records} total voting records and {number_of_batches} batches in the data sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_file': '/home/michael/git_repos/georgia_election_data/source_data/20190709/1996.zip', 'line_count': 4644200, 'batches': [(0, 999999), (1000000, 1999999), (2000000, 2999999), (3000000, 3999999), (4000000, 4644199)]}\n"
     ]
    }
   ],
   "source": [
    "print(ret_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fwf_to_sqlitedb(file_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes the source data files and builds a sqlite database.\n",
    "    CSVs are being used in lieu of pandas dataframes for the source data because\n",
    "    the memory footprint and CPU overhead of 78 million records requires an\n",
    "    un-needed quantity of those resources.\n",
    "    \"\"\"\n",
    "    full_path_to_db = f'{working_directory}/{database_location}/{dest_db_name}'\n",
    "\n",
    "    \n",
    "    db = sqlite3.connect(full_path_to_db)\n",
    "\n",
    "    # now load the files\n",
    "\n",
    "    pre_2012_range = set(range(1996,2013))\n",
    "    post_2013_range = set(range(2013,2020))\n",
    "\n",
    "    cur_file_name = file_dict['source_file']\n",
    "    \n",
    "    # collect the records\n",
    "    gen = get_n_lines_iterator(cur_file_name)\n",
    "        \n",
    "    for cur_range in tqdm(file_dict['batches'], desc=f'Processing batch in {os.path.basename(cur_file_name).split(\".\")[0]}'):\n",
    "        start_i, end_i = cur_range\n",
    "        cur_record_list = [next(gen) for r in range(start_i, end_i)]\n",
    "        if int(os.path.basename(cur_file_name).split(\".\")[0]) in pre_2012_range:\n",
    "            parsed_data = list(map(parse_function_2012_prior,cur_record_list))\n",
    "\n",
    "        elif int(os.path.basename(cur_file_name).split(\".\")[0]) in post_2013_range:\n",
    "            parsed_data = list(map(parse_function_2013_post,cur_record_list))\n",
    "\n",
    "        #print(f\"Loading {os.path.basename(f)} into the sqlite database\")\n",
    "        c = db.cursor()\n",
    "        c.executemany(f\"INSERT INTO {dest_db_table_name} VALUES (?,?, ?, ?, ?, ?, ?, ?, ?)\", parsed_data)\n",
    "        db.commit()\n",
    "        #print(f\"Loaded {os.path.basename(f)} into the sqlite database\")\n",
    "\n",
    "    db.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    c = db.cursor()\n",
    "    c.execute(f'''\n",
    "               CREATE TABLE {dest_db_table_name}(\n",
    "               vintage INT,\n",
    "               county_no TEXT,\n",
    "               reg_no TEXT, \n",
    "               election_date TEXT,\n",
    "               election_type TEXT, \n",
    "               party TEXT,\n",
    "               absentee BOOLEAN,\n",
    "               supplemental BOOLEAN,\n",
    "               provisional BOOLEAN) \n",
    "            ''')\n",
    "    db.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing batch in 1996:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cur record list is 999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7b3be4d49a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_fwf_to_sqlitedb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-e5e70bcb668b>\u001b[0m in \u001b[0;36mconvert_fwf_to_sqlitedb\u001b[0;34m(file_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(f\"Loading {os.path.basename(f)} into the sqlite database\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"INSERT INTO {dest_db_table_name} VALUES (?,?, ?, ?, ?, ?, ?, ?, ?)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(f\"Loaded {os.path.basename(f)} into the sqlite database\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "convert_fwf_to_sqlitedb(ret_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "   if drop_table:\n",
    "        c = db.cursor()\n",
    "        c.execute(f'drop table if exists {dest_db_table_name};')\n",
    "        db.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the database\n",
    "\n",
    "The following code generates the sqlite database from the source data. This process should take 5-10 minutes to complete, depending on available computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db\n",
      "The curent database name still exists. Type Y if you want to re-create the databaseY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Individual file processing progress: 100%|██████████| 24/24 [00:00<00:00, 54648.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 to process.\n",
      "Creating database in the /home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db folder\n",
      "All Files Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1996.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/24 [00:34<13:09, 34.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1996.zip into the sqlite database\n",
      "Loading 1997.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/24 [00:42<09:42, 26.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1997.zip into the sqlite database\n",
      "Loading 1998.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 3/24 [01:09<09:18, 26.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1998.zip into the sqlite database\n",
      "Loading 1999.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 4/24 [01:14<06:40, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1999.zip into the sqlite database\n",
      "Loading 2000.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 5/24 [01:52<08:04, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000.zip into the sqlite database\n",
      "Loading 2001.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [01:58<05:56, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2001.zip into the sqlite database\n",
      "Loading 2002.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 7/24 [02:27<06:22, 22.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2002.zip into the sqlite database\n",
      "Loading 2003.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 8/24 [02:32<04:37, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2003.zip into the sqlite database\n",
      "Loading 2004.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 9/24 [03:22<06:43, 26.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2004.zip into the sqlite database\n",
      "Loading 2005.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 10/24 [03:29<04:53, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2005.zip into the sqlite database\n",
      "Loading 2006.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 11/24 [03:57<05:00, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2006.zip into the sqlite database\n",
      "Loading 2007.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [04:03<03:37, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2007.zip into the sqlite database\n",
      "Loading 2008.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 13/24 [05:16<06:20, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2008.zip into the sqlite database\n",
      "Loading 2009.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [05:23<04:20, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2009.zip into the sqlite database\n",
      "Loading 2010.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 15/24 [06:00<04:26, 29.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2010.zip into the sqlite database\n",
      "Loading 2011.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 16/24 [06:11<03:10, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2011.zip into the sqlite database\n",
      "Loading 2012.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 17/24 [07:06<03:52, 33.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2012.zip into the sqlite database\n",
      "Loading 2013.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 18/24 [07:13<02:32, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2013.zip into the sqlite database\n",
      "Loading 2014.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 19/24 [07:50<02:24, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2014.zip into the sqlite database\n",
      "Loading 2015.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [07:56<01:27, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2015.zip into the sqlite database\n",
      "Loading 2016.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 21/24 [09:03<01:46, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016.zip into the sqlite database\n",
      "Loading 2017.zip into the sqlite database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [09:16<00:57, 28.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2017.zip into the sqlite database\n",
      "Loading 2018.zip into the sqlite database\n"
     ]
    }
   ],
   "source": [
    "# Set the path for outputting the database file\n",
    "\n",
    "original_data_full_path = working_root_folder + original_data_folder\n",
    "database_out_path = working_root_folder +  '/database/'\n",
    "\n",
    "# the sqlite database will be saved here\n",
    "database_name = 'ga_elect2.db'\n",
    "\n",
    "# Check first to see if this file exists\n",
    "# If so, we want to give the option to delete it\n",
    "# since it may be locked or corrupted\n",
    "\n",
    "print(database_out_path + database_name)\n",
    "is_database_exists = os.path.exists(database_out_path + database_name)\n",
    "\n",
    "confirm = None \n",
    "\n",
    "if is_database_exists:\n",
    "    confirm = input(\"The curent database name still exists. Type Y if you want to re-create the database\")\n",
    "\n",
    "if confirm == 'Y':    \n",
    "    convert_fwf_to_sqlitedb(original_data_full_path, database_out_path + database_name)\n",
    "else:\n",
    "    print(\"Keeping existing database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function/\n",
    "\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "c.execute('''SELECT count(*) FROM ga_elect_data''')\n",
    "assert(c.fetchall()[0][0]) == 76453445\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding helper tables\n",
    "\n",
    "There is one helper table that will also be added to the database. This helper table maps the election_type field to indicate if the field reflects a _primary_ election, a _primary runoff_ election, a _general_ election, or another type of vote.\n",
    "\n",
    "This mapping is needed because the election_type coding has either 1) not been consistent from election to election or 2) a new election_type code was created when a ballot combined two types of elections. For example, a general election added to a recall election.\n",
    "\n",
    "The repo includes a file `election_type_mapping.csv` that contains a manual classification between the election types and the above manual classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /home/michaelhandelman/ga_election_code/ga_elect/database/ga_elect2.db\n",
      "found helper data here:/home/michaelhandelman/ga_election_code/ga_elect/election_type_mapping.csv\n",
      "Table created\n",
      "Data uploaded\n"
     ]
    }
   ],
   "source": [
    "print(f\"Opening {database_out_path + database_name}\")\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "\n",
    "manual_classification_file_loc = working_root_folder + '/election_type_mapping.csv'\n",
    "\n",
    "if os.path.exists(manual_classification_file_loc):\n",
    "    print(\"found helper data here:\" + manual_classification_file_loc)\n",
    "\n",
    "    \n",
    "# load the file into a list of tuples\n",
    "\n",
    "input_str = open(manual_classification_file_loc, 'r').readlines()\n",
    "input_str_list = [tuple(l.strip().split(',')) for l in input_str]\n",
    "# remove header\n",
    "input_str_list = input_str_list[1:]\n",
    "\n",
    "c.execute('drop table if exists ga_elect_manual_classification;')\n",
    "db.commit()\n",
    "c = db.cursor()\n",
    "c.execute('''\n",
    "           CREATE TABLE ga_elect_manual_classification(\n",
    "           election_type_index INT,\n",
    "           election_type TEXT,\n",
    "           election_type_description TEXT, \n",
    "           manual_classification TEXT)\n",
    "           ''')\n",
    "db.commit()\n",
    "print(\"Table created\")\n",
    "\n",
    "c = db.cursor()\n",
    "c.executemany(\"INSERT INTO ga_elect_manual_classification VALUES (?,?, ?, ?)\", input_str_list)\n",
    "db.commit()\n",
    "print(\"Data uploaded\")\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming that this new table was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Function/\n",
    "\n",
    "db = sqlite3.connect(database_out_path + database_name)\n",
    "c = db.cursor()\n",
    "c.execute('''SELECT count(*) FROM ga_elect_manual_classification''')\n",
    "assert(c.fetchall()[0][0] == 37)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
